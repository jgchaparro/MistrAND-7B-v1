{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building training dataset from OASST2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.convert_to_andalusian_spanish import AndalusianConversor\n",
    "from transformers import AutoTokenizer\n",
    "import plotly.express as px\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join('data', 'raw', '2023-11-05_oasst2_all.messages.jsonl')\n",
    "raw_df = pd.read_json(filename, lines=True)\n",
    "\n",
    "# Filter for lang = 'es'\n",
    "raw_df = raw_df[raw_df['lang'] == 'es']\n",
    "\n",
    "# Drop unnecessary columns\n",
    "to_drop = ['user_id', 'created_date', 'lang', 'emojis', 'model_name']\n",
    "raw_df.drop(columns = to_drop, inplace = True)\n",
    "\n",
    "print(raw_df.shape)\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design working dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create base copy\n",
    "filtered_df = raw_df.copy()\n",
    "\n",
    "# Drop rows where review_result is 1\n",
    "filtered_df = filtered_df[filtered_df['review_result'] == 1]\n",
    "\n",
    "# Keep needed columns\n",
    "to_keep = ['message_id', 'text', 'role', 'message_tree_id', 'parent_id']\n",
    "filtered_df = filtered_df[to_keep]\n",
    "\n",
    "# Convert IDs to integers\n",
    "id_dict = {k: v for v, k in enumerate(filtered_df['message_id'].unique(), start=1)}\n",
    "to_map = ['message_id', 'message_tree_id', 'parent_id']\n",
    "for col in to_map:\n",
    "    filtered_df[col] = filtered_df[col].map(id_dict)\n",
    "\n",
    "# Fill NaNs with 0\n",
    "to_fill = ['message_tree_id', 'parent_id']\n",
    "filtered_df[to_fill] = filtered_df[to_fill].fillna(0).astype(int)\n",
    "\n",
    "# Set message_id as index\n",
    "filtered_df.set_index('message_id', inplace=True)\n",
    "\n",
    "print(filtered_df.shape)\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save checkpoint\n",
    "checkpoint = {'filtered_df': filtered_df}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain 2-element conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load checkpoint\n",
    "temp_df = checkpoint['filtered_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each row in aux_df, create a column with the IDs of the messages in the same thread\n",
    "def get_path(row: pd.Series,\n",
    "             df: pd.DataFrame = temp_df) -> list:\n",
    "    \"\"\"\n",
    "    Generate a list of message IDs that are in the same thread as the current message.\n",
    "\n",
    "    Args:\n",
    "    row (pd.Series): A row from a DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of message IDs.\n",
    "    \"\"\"\n",
    "\n",
    "    path = [row.name]\n",
    "    parent_id = row['parent_id']\n",
    "    while parent_id != 0:\n",
    "        path.append(parent_id)\n",
    "        parent_id = df.loc[parent_id, 'parent_id']\n",
    "\n",
    "    # Reverse the list\n",
    "    path = path[::-1]\n",
    "\n",
    "    return path\n",
    "\n",
    "temp_df['path'] = temp_df.apply(get_path, axis=1)\n",
    "display(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract paths with 2 elements\n",
    "mask = temp_df['path'].apply(len) == 2\n",
    "two_element_paths = temp_df[mask]['path'].tolist()\n",
    "print('Two-element paths:', len(two_element_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_conversation_dict(path: list,\n",
    "                       df: pd.DataFrame = temp_df) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build a conversation from a list of message IDs as a JSON object.\n",
    "\n",
    "    Args:\n",
    "    path (list): A list of message IDs.\n",
    "    df (pd.DataFrame): A DataFrame with the messages.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame with the conversation.\n",
    "    \"\"\"\n",
    "\n",
    "    conversation_dict = {\n",
    "        'input': df.loc[path[0], 'text'],\n",
    "        'output': df.loc[path[1], 'text'],\n",
    "        'path': path,\n",
    "    }\n",
    "\n",
    "    return conversation_dict\n",
    "\n",
    "conversation_dict_list = [build_conversation_dict(path) for path in two_element_paths]\n",
    "conversation_df = pd.DataFrame(conversation_dict_list)\n",
    "print(conversation_df.shape)\n",
    "conversation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save checkpoint\n",
    "checkpoint['conversation_df'] = conversation_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Andalusian transliteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load checkpoint\n",
    "conversation_df = checkpoint['conversation_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the text to Andalusian Spanish\n",
    "conversor = AndalusianConversor()\n",
    "conversation_df['input'] = conversation_df['input'].apply(conversor.convert)\n",
    "conversation_df['output'] = conversation_df['output'].apply(conversor.convert)\n",
    "print(f'Final shape: {conversation_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test conversor\n",
    "conversor.convert('Paula tiene un perro llamado Mushu, Â¿a que todos amamos a Mushu? ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Final shape: {conversation_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show results\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "conversation_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save checkpoint\n",
    "checkpoint['andalusian_transcript'] = conversation_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trim maximum token length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load checkpoint\n",
    "temp_df = checkpoint['andalusian_transcript']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "base_model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    padding_side=\"left\",\n",
    "    add_eos_token=True,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input length distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_lengths = temp_df['input'].apply(tokenizer.tokenize).apply(len)\n",
    "\n",
    "# Plot input lengths\n",
    "fig = px.histogram(input_lengths, title='Input Length Distribution')\n",
    "fig.update_layout(title_x=0.5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative distribution\n",
    "fig = px.histogram(input_lengths, \n",
    "                   cumulative=True, \n",
    "                   title='Input Length Cumulative Distribution', \n",
    "                   histnorm='probability',\n",
    "                   labels = {'value': 'Input Length', \n",
    "                             'probability': 'Cumulative Probability',\n",
    "                             'variable': 'Frequency'})\n",
    "fig.update_layout(title_x=0.5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute percentage of inputs that are longer than n tokens\n",
    "max_length = 250\n",
    "mask = input_lengths > max_length\n",
    "long_inputs = input_lengths[mask]\n",
    "percentage = len(long_inputs) / len(input_lengths) * 100\n",
    "print(f'Percentage of inputs longer than {max_length} tokens: {percentage:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output length distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output length distribution\n",
    "output_lengths = temp_df['output'].apply(tokenizer.tokenize).apply(len)\n",
    "\n",
    "# Plot output lengths\n",
    "fig = px.histogram(output_lengths, title='Output Length Distribution')\n",
    "fig.update_layout(title_x=0.5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative distribution\n",
    "fig = px.histogram(output_lengths, \n",
    "                   cumulative=True, \n",
    "                   title='Output Length Cumulative Distribution', \n",
    "                   histnorm='probability',\n",
    "                   labels = {'value': 'Output Length', \n",
    "                             'probability': 'Cumulative Probability',\n",
    "                             'variable': 'Frequency'})\n",
    "fig.update_layout(title_x=0.5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute percentage of outputs that are longer than n tokens\n",
    "max_length = 1600\n",
    "mask = output_lengths > max_length\n",
    "long_outputs = output_lengths[mask]\n",
    "percentage = len(long_outputs) / len(output_lengths) * 100\n",
    "print(f'Percentage of outputs longer than {max_length} tokens: {percentage:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combined distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set formatting function\n",
    "def formatting_func(example):\n",
    "    text = f\"### PreÆ¨unÊa: {example['input']}\\n ### ÎeÑpueÑÊa: {example['output']}\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply formatting function\n",
    "temp_df['formatted'] = temp_df.apply(formatting_func, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined length distribution\n",
    "combined_lengths = temp_df['formatted'].apply(tokenizer.tokenize).apply(len)\n",
    "\n",
    "# Plot combined lengths\n",
    "fig = px.histogram(combined_lengths, title='Combined Length Distribution')\n",
    "fig.update_layout(title_x=0.5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative distribution\n",
    "fig = px.histogram(combined_lengths, \n",
    "                   cumulative=True, \n",
    "                   title='Combined Length Cumulative Distribution', \n",
    "                #    histnorm='probability',\n",
    "                   labels = {'value': 'Combined Length', \n",
    "                             'probability': 'Cumulative Probability',\n",
    "                             'variable': 'Frequency'})\n",
    "fig.update_layout(title_x=0.5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute percentage of combined lengths that are longer than n tokens\n",
    "max_length = 1250\n",
    "mask = combined_lengths > max_length\n",
    "long_combined = combined_lengths[mask]\n",
    "percentage = len(long_combined) / len(combined_lengths) * 100\n",
    "print(f'Percentage of combined lengths longer than {max_length} tokens: {percentage:.2f}% (n = {len(long_combined)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute percentage of combined lengths that are shorter than n tokens\n",
    "max_length = 125\n",
    "mask = combined_lengths < max_length\n",
    "short_combined = combined_lengths[mask]\n",
    "percentage = len(short_combined) / len(combined_lengths) * 100\n",
    "print(f'Percentage of combined lengths shorter than {max_length} tokens: {percentage:.2f}% (n = {len(short_combined)})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trim to selected length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_allowed_length = 1250\n",
    "print(f'Number of examples before filtering: {len(temp_df)}')\n",
    "temp_df = temp_df[combined_lengths <= max_allowed_length]\n",
    "print(f'Number of examples after filtering: {len(temp_df)}')\n",
    "temp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save checkpoint\n",
    "checkpoint['trimmed_transcript'] = temp_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load checkpoint\n",
    "full_df = checkpoint['trimmed_transcript']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retain only needed columns\n",
    "to_keep = ['input', 'output']\n",
    "full_df = full_df[to_keep].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the following modes must be set:\n",
    "* **preprod**: used for hyperparameter tuning.\n",
    "* **prod**: used for final model fine-tuning.\n",
    "\n",
    "It only affects the final file naming, but ensures that the naming conventions are consistent accross the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set saving mode\n",
    "mode = 'prod' # Select either 'preprod' or 'prod'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set saving settings\n",
    "directory = os.path.join('data', 'processed')\n",
    "filename = f'conversations_2E_ES_AND_{mode}_full.jsonl'\n",
    "full_path = os.path.join(directory, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle dataset\n",
    "full_df = full_df.sample(frac=1, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as .jsonl\n",
    "full_df.to_json(full_path, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and eval sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you plan to track the validation loss during training, it is recommended to set the number of evaluation instances to a fixed low number: since all samples are tested, keeping the usual 20 % of the data for evaluation results in longer training times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set saving settings\n",
    "n_eval_instances = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "train_df = full_df[:-n_eval_instances]\n",
    "val_df = full_df[-n_eval_instances:]\n",
    "print(f'Training set shape: {train_df.shape}')\n",
    "print(f'Validation set shape: {val_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training set as .jsonl\n",
    "filename = f'conversations_2E_ES_AND_{mode}_train.jsonl'\n",
    "filepath = os.path.join(directory, filename)\n",
    "train_df.to_json(filename, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save validation set as .jsonl\n",
    "filename = f'conversations_2E_ES_AND_{mode}_val.jsonl'\n",
    "filepath = os.path.join(directory, filename)\n",
    "val_df.to_json(filename, orient='records', lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
